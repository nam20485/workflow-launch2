# **Application Implementation Specification: PCB Renderer LLM Plugin**

## **New Application**

**App Title:** PCB Renderer LLM Plugin

## **Development Plan**

**Summary:**

This plugin is developed as a distinct "Phase 2" extension to the core PCB Renderer. It operates under a strict architectural mandate of **complete decoupling**: the plugin depends on the core renderer's output, but the core renderer functions perfectly without the plugin. This separation allows the core to remain a lightweight, deterministic tool suitable for CI/CD pipelines, while the plugin serves as a heavyweight, intelligent interactive assistant.

The development roadmap is structured into four expanded phases:

1. **Data Contract & State Export (Core Modification):**  
   * Before the plugin can exist, the Core Renderer must be enhanced to support a high-fidelity data dump. This involves implementing the \--export-json flag.  
   * **Crucial Detail:** The export cannot simply be a raw memory dump. It must be a *sanitized, semantic graph*. Geometry (raw points) is less important here than Topology (Netlists, Component relationships). This phase involves creating a serializer that strips unnecessary rendering data (like color palettes) while enriching logical data (like Net connectivity graphs) to optimize for the LLM's context window.  
2. **Plugin Core & CLI Wrapper:**  
   * Implementation of the llm-plugin entry point using typer or argparse.  
   * Development of the input parser that ingests the JSON contract from Phase 1\.  
   * Creation of the "Orchestrator" pattern which determines whether a user's request requires a simple lookup (e.g., "What is error E01?") or full-board analysis (e.g., "Why is this trace unroutable?").  
3. **Prompt Engineering & Context Management:**  
   * This is the most complex phase. It requires designing specific prompt templates for distinct tasks: **Error Explanation**, **Fix Suggestions**, and **Design Heuristics**.  
   * **Context Strategy:** Application of token-limiting strategies. For large boards, the plugin cannot send the entire JSON to the API. We must implement a "Windowing" or "Relevance Filter" system that only sends the components and traces directly involved in a specific error (plus their immediate neighbors).  
   * **Prompt Architecture:** Define a dual-layer prompt system:  
     * **System Prompt:** Sets the persona ("Expert ECAD Engineer"), tone (professional, concise), and constraints (no hallucinated features).  
     * **User Prompt:** Contains the serialized local context and the specific error metadata.  
4. **Client Integration:**  
   * Wiring up the LLM client (standardizing on the OpenAI API format to allow swapping between OpenAI, Anthropic, or local open-weights models like Llama 3).  
   * Implementing robust error handling for API timeouts, rate limits, and context length exceeded errors.

**See llm\_plugin\_architecture.md for specific architectural details.**

## **Description**

The **PCB Renderer LLM Plugin** is an intelligent, optional add-on tool that consumes the structured machine-readable output of the PCB Renderer. Its purpose is to bridge the gap between rigorous technical validation and human understanding. It provides natural-language debugging assistance, context-aware error explanations, and high-level design insights using Large Language Models.

## **Overview**

In the ecosystem of this application, the **Core Renderer** acts as the "Code Compiler" or "Building Inspector"—it is strict, binary, and speaks in error codes (e.g., DANGLING\_TRACE, MISSING\_BOUNDARY). It does not care *why* a mistake was made, only that it exists.

The **LLM Plugin** acts as the "Senior Engineer" or "Mentor" sitting next to the user. It translates the inspector's rejection into actionable advice. Instead of just saying "Error: Trace T1 has \<2 points," the plugin analyzes the surrounding geometry to say: *"It looks like you started drawing a trace from U1-Pin4 but didn't finish it. This often happens when a routing tool crashes or a click isn't registered. Since this pin connects to the 5V rail, you likely want to route this to the nearby VCC via at (10, 20)."*

This distinction is vital: The Core provides **Correctness**, while the Plugin provides **Productivity**.

## **Document Links**

* llm\_plugin\_architecture.md \- Primary architecture source, detailing the JSON contract and data flow.  
* architecture\_guide\_v2.md \- Context for the core system, specifically the error code definitions.

## **Requirements**

### **Functional Requirements**

* **Input Consumption (The Data Contract):**  
  * Must accept a file path to the specific JSON output generated by pcb-render \--export-json.  
  * Must validate the schema version of the input JSON to ensure compatibility with the prompt templates.  
  * Must handle cases where the input JSON represents a *valid* board (no errors) versus an *invalid* board (list of error objects).  
* **Error Explanation (The "Translator"):**  
  * Must iterate through the errors list in the input.  
  * For each error, it must generate a plain-English explanation that defines the technical term (e.g., "What is an Annular Ring?") and explains the specific instance of failure.  
  * Must prioritize errors by severity—addressing "Connectivity" issues before "Cosmetic" warnings.  
* **Fix Suggestions (The "Pair Programmer"):**  
  * Must parse the specific "Local Context" of an error. For a dangling trace, it must identify the nearest valid connection points (Pads or Vias) within a reasonable radius.  
  * Must generate concrete, syntax-correct JSON snippets that the user could theoretically copy/paste to fix the issue.  
  * **Patch Application:** The suggestion must include the JSON Path (e.g., $.traces\[3\].segments) indicating exactly where the snippet should be applied, facilitating future automated patching features.  
  * **Safety constraint:** The plugin must explicit state that these are *suggestions* and not guaranteed to be manufactured correctly.  
* **Design Analysis (The "Health Check"):**  
  * Must calculate derived statistics that are not present in the raw JSON:  
    * **Trace Density:** (Total Trace Length / Board Area).  
    * **Via Aspect Ratio:** (Board Thickness (assumed) / Via Drill Diameter).  
  * Must interpret these stats to offer "Soft" advice (e.g., "Your via density is very high in the top-left quadrant; consider spacing these out to improve manufacturability").  
* **CLI Interface:**  
  * explain \<json\_file\>: Detailed breakdown of every error found.  
  * suggest-fixes \<json\_file\>: Targeted code patches for specific errors.  
  * analyze \<json\_file\>: High-level design review of a valid (or invalid) board.

### **Non-Functional Requirements**

* **Decoupling & Resilience:**  
  * The plugin must function as a completely standalone executable. It must **not** import modules from the core renderer directly (no from pcb\_renderer import ...), ensuring that changes to the core's rendering logic do not break the plugin as long as the JSON contract remains stable.  
  * If the LLM API is unreachable, the plugin must fail gracefully, perhaps falling back to static, template-based error descriptions.  
* **Flexibility & Configuration:**  
  * Must allow configuration of the API\_BASE\_URL and API\_KEY via environment variables, supporting both proprietary APIs (OpenAI) and local inference servers (Ollama/LocalAI).  
* **Context Window Optimization:**  
  * The system must never blindly send the entire board file to the LLM. It must implement a "Focus Strategy": extracting only the relevant 5-10 components surrounding an error to keep token usage low and precision high.

## **Features**

1. **Natural Language Error Context:**  
   * Converts cryptic error codes into educational content.  
   * *Example:*  
     * **Input:** Code: INVALID\_DIAMETER, Msg: Via V1 drill (0.5) \>= annular ring (0.5)  
     * **Output:** *"The drill bit for Via V1 is the same size as the copper pad itself. This means when the manufacturer drills the hole, they might drill away all the copper connection, breaking the circuit. You need to either decrease the drill size to 0.3mm or increase the pad diameter to 0.7mm."*  
2. **Context-Aware Suggestions:**  
   * Uses board metadata (netlist and component positions) to hallucinate *valid* corrections.  
   * *Example:* If a trace ends in empty space, the plugin looks for the nearest pad *with the same Net ID*. If it finds one 2mm away, it suggests: *"Extend trace segment by (2.0, 0.0) to connect to R1-Pin2."*  
3. **Design "Health Check":**  
   * Analyzes component placement and routing complexity to flag potential manufacturing risks that aren't strict errors.  
   * *Example:* Detecting that 90% of components are on the top layer while the bottom is empty, suggesting a more balanced stack-up to prevent board warping during reflow soldering.  
4. **Interactive Mode (Future / Beta):**  
   * A REPL (Read-Eval-Print Loop) interface where the user can query the board state.  
   * *User:* "Show me all nets connected to U1."  
   * *Plugin:* "U1 connects to: VCC (Pin 1), GND (Pin 2), and SIGNAL\_A (Pin 3)."

## **Test Cases**

* **Unit Tests:**  
  * test\_error\_explanation\_prompt: Verify that the prompt template correctly inserts the JSON snippet and error message without truncating vital data.  
  * test\_suggestion\_formatting: Feed the system a mock LLM response containing a JSON block and verify the regex parser extracts it correctly.  
  * test\_context\_filter: Feed the system a board with 1000 components and an error on Component A. Verify that the "Context Builder" only selects Component A and its immediate neighbors for the prompt, filtering out the other 990 components.  
* **Integration Tests:**  
  * **End-to-End Workflow:**  
    1. Run pcb-render on board\_kappa.json (which is known to fail).  
    2. Capture the output debug\_kappa.json.  
    3. Run llm-plugin explain debug\_kappa.json.  
    4. Assert that the stdout contains the words "trace", "points", and "connection".  
  * **Hallucination Check:** Feed the plugin a board with a component named "FLUX\_CAPACITOR". Ensure the LLM doesn't invent fake electrical properties for it, but instead relies *only* on the geometry provided in the JSON.

## **Logging**

* **Operational Logging:** Logs API connection status, response latency, and token usage statistics (Input/Output tokens) to help the user manage costs.  
* **Audit Logging:** In debug mode, saves the full raw prompt sent to the LLM and the raw response received. This is critical for debugging prompt engineering issues.  
* **Output Format:** The primary user output is Markdown-formatted text to stdout, utilizing bolding and code blocks for readability in terminal emulators.

## **Containerization: Docker**

The plugin can be containerized separately or as a layer on top of the core renderer. A separate composition is preferred to keep the images small.

\# Start with a slim python image  
FROM python:3.11-slim

WORKDIR /app

\# Install only the plugin dependencies (no matplotlib required here)  
COPY pyproject.toml .  
\# Note: This assumes a project structure where optional-deps includes 'llm'  
RUN pip install ".\[llm\]"

\# Copy source code  
COPY . .

\# Entrypoint targets the plugin module specifically  
ENTRYPOINT \["python", "-m", "llm\_plugin"\]

## **Documentation**

* **Plugin README:**  
  * Specific instructions on obtaining and setting environment variables (OPENAI\_API\_KEY, etc.).  
  * Guide on how to export data from the core renderer (--export-json).  
* **Prompt Library:**  
  * A document (internal or external) cataloging the system prompts used. This is effectively the "Source Code" of the plugin's intelligence.  
  * *Example:* "The Error Explainer uses a 'Persona' prompt that instructs the model to be helpful but concise, avoiding flowery language."

## **Acceptance Criteria**

1. **Data Ingestion:** The plugin successfully loads and validates the schema of the debug.json file exported from the core app.  
2. **Analysis Quality:** The explain command outputs text that correctly identifies the specific error code present in the file and provides a description that matches the definitions in architecture\_guide\_v2.md.  
3. **Independence:** The plugin runs successfully in an environment where matplotlib and numpy (core dependencies) are **not** installed, proving true decoupling.  
4. **Failure Handling:** If the LLM API returns a 500 error, the plugin catches the exception and prints a user-friendly message ("Unable to contact AI assistant") rather than a Python stack trace.

## **Language**

* **Primary:** Python  
* **Version:** 3.11+ (Matching the Core Renderer for developer convenience, though not strictly required due to decoupling).

## **Frameworks, Tools, Packages**

* **Core CLI:** typer is preferred over argparse for the plugin because it supports easy subcommand creation (explain, analyze) and automatic help generation, which fits the "Tool" paradigm better.  
* **LLM Client:** openai (Official Python SDK) or langchain (if complex chains are needed). We will start with the raw openai client to reduce dependency bloat, as our prompt chains are relatively simple (Single Turn).  
* **Data Validation:** pydantic. Ideally, the plugin reuses the *schema definitions* from the core models if they are packaged as a shared library. If not, the plugin maintains a simplified, "Loose" version of the Pydantic models that are tolerant of missing fields (Robustness Principle).

## **Project Structure**

The file structure is organized to separate the CLI, the Logic (Analyzer), and the IO (Client).

llm-plugin/  
├── pyproject.toml          \# Plugin-specific dependencies  
├── llm\_plugin/  
│   ├── \_\_init\_\_.py  
│   ├── \_\_main\_\_.py         \# Entry point  
│   ├── cli.py              \# Typer app definition (Commands: explain, analyze)  
│   ├── prompts.py          \# Storage for long string templates (System Prompts)  
│   ├── client.py           \# Wrapper around OpenAI/Local API (Retries, Error Handling)  
│   ├── context.py          \# Logic for filtering/windowing the large JSON board  
│   └── analyzer.py         \# Heuristic math for "Health Check" stats  
└── tests/  
    ├── test\_plugin.py      \# CLI invocation tests  
    └── test\_prompts.py     \# Verification of template rendering

## **GitHub**

**Repo:** https://github.com/intel-agency/pcb-renderer

**Branch:** main (Likely a subdirectory plugins/llm or a separate repository depending on governance).